{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bfs\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os.path\n",
    "import os\n",
    "from Crypto.Cipher import AES\n",
    "import binascii\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all acode (runner unique code) in a run event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML('<iframe src=https://services.datasport.com/2015/lauf/transviamala/alfaw.htm width=1000 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_acode(url):\n",
    "    alpha_page = rq.get(url)\n",
    "    alpha_page_soup = bfs(alpha_page.text, 'html5lib')\n",
    "\n",
    "    runners = alpha_page_soup.body.findAll('span', attrs={'class': 'myds'})\n",
    "    \n",
    "    return {runner['acode']: str.strip(runner.text) for runner in runners}\n",
    "\n",
    "def get_all_acode_from_run_event(url, file=False):\n",
    "    \n",
    "    if file and os.path.isfile(file):\n",
    "        print('Read acode from file: ' + file)\n",
    "        return pd.read_csv(file, index_col='acode').to_dict()['name']\n",
    "    \n",
    "    data = []\n",
    "    page = rq.get(url)\n",
    "    soup = bfs(page.text, 'html5lib')\n",
    "    table_links = soup.select('font > a[href*=ALF]')\n",
    "    all_acode = {}\n",
    "    if url[-1] != '/':\n",
    "        url += '/'\n",
    "    for idx, link in enumerate(table_links):\n",
    "        full_link = url + link['href']\n",
    "        \n",
    "        #print(str(idx+1) + '/' + str(len(table_links)) + ' - Processing ' + full_link)\n",
    "\n",
    "        all_acode = {**all_acode, **get_all_acode(full_link)}\n",
    "    if file:\n",
    "        print('Write acode in file: ' + file)\n",
    "        pd.Series(all_acode).to_csv(file, header=['name'], index_label='acode')\n",
    "        \n",
    "    return all_acode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#acode_list = get_all_acode_from_run_event('https://services.datasport.com/2009/diverse/trophy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(acode_list.items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get run events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML('<iframe src=https://www.datasport.com/en/Calendar/ width=1000 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_params_calendar():\n",
    "    calendar_page = rq.get('https://www.datasport.com/en/Calendar/')\n",
    "    calendar_soup = bfs(calendar_page.text, 'html5lib')\n",
    "\n",
    "    selector_table = calendar_soup.find('table', attrs={'id': 'ds-calendar-header'})\n",
    "\n",
    "    available_params = {}\n",
    "    for selector in selector_table.findAll('select'):\n",
    "        available_params[selector['name']] = {option.text: option['value'] for option in selector.findAll('option')}\n",
    "\n",
    "    return available_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calendar_available_params = get_all_params_calendar()\n",
    "#calendar_available_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all run events url in a calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_run_events_url(year=2009, month=1, country='CCH', sport='Running'):\n",
    "\n",
    "    calendar_params = {\n",
    "        'dr': '',\n",
    "        'lastQuery': 'D147BC896417D2D2B96FA1AADD893731',\n",
    "        'eventsearch': '',\n",
    "        'eventservice': 'all',\n",
    "        'start': 1,\n",
    "        'etyp': sport,\n",
    "        'eventlocation': country,\n",
    "        'eventmonth': month,\n",
    "        'eventyear': year,\n",
    "    }\n",
    "\n",
    "    calendar_page = rq.post('https://www.datasport.com/en/Calendar/', data = calendar_params)\n",
    "    calendar_soup = bfs(calendar_page.text, 'html5lib')\n",
    "\n",
    "    table = calendar_soup.find('table', attrs={'id': 'ds-calendar-body'})\n",
    "\n",
    "    all_event_url = {}\n",
    "    for row in table.findAll('tr'):\n",
    "        columns = row.findAll('td')\n",
    "        if len(columns) >= 4:\n",
    "            url = columns[4].find('a')\n",
    "            if url:\n",
    "                all_event_url[url['href']] = {\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'country': country,\n",
    "                    'sport': sport,\n",
    "                    'full_date': str.strip(columns[0].text),\n",
    "                    'name': str.strip(columns[1].text),\n",
    "                }\n",
    "\n",
    "    return all_event_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_run_events_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all run event urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_run_events():\n",
    "    run_events = {}\n",
    "    calendar_available_params = get_all_params_calendar()\n",
    "    for year_text, year_value in calendar_available_params['eventyear'].items():\n",
    "        if year_value != 'all':\n",
    "            for month_text, month_value in calendar_available_params['eventmonth'].items():\n",
    "                if month_value != 'all':\n",
    "                    print('Processing: Year ' + year_value + ' / Month ' + month_value)\n",
    "                    run_events = {**run_events,  **get_run_events_url(year_value, month_value)}\n",
    "                    time.sleep(random.uniform(0.5, 2))\n",
    "    return run_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_events = get_all_run_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_events_df = pd.DataFrame(run_events).T\n",
    "#run_events_df.index.name = 'url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_events_df.to_csv('Data/run_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head Data/run_events.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_events_df = pd.read_csv('Data/run_events.csv')\n",
    "run_events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all acode in all runs from 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_events_df_2009_2015 = run_events_df[[year >= 2009 and year < 2016 for year in run_events_df['year']]]\n",
    "#run_events_df_2009_2015.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run_events_df_2009_2015.to_csv('Data/run_events_2009_2015.csv', index_label='acode_index')\n",
    "!head Data/run_events_2009_2015.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_events_df_2009_2015 = pd.read_csv('Data/run_events_2009_2015.csv', index_col='acode_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_all_acode_from_list_run_event(run_events, path='Data/acode_2009_2015/'):\n",
    "    for run_event in run_events.itertuples():\n",
    "        print('Processing: Run \"' + run_event.name + '\" / Date ' + run_event.full_date + ' / Url ' + run_event.url)\n",
    "        get_all_acode_from_run_event(run_event.url, path + str(run_event.Index) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './Data/acode_2009_2015/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_acode_2009_2015 = get_all_acode_from_list_run_event(run_events_df_2009_2015, PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definir une mÃ©thode\n",
    "\n",
    "# get all data and remove the double\n",
    "file_list = os.listdir(PATH_TO_DATA)\n",
    "result_dataframe = pd.read_csv(PATH_TO_DATA + '1000.csv')\n",
    "for file in file_list:\n",
    "    pd.concat([result_dataframe, pd.read_csv(PATH_TO_DATA+file)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(result_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_NAME = 'unique_acode_2009_2015.csv'\n",
    "if(len(result_dataframe['acode'].unique()) == len(result_dataframe)):\n",
    "    result_dataframe.to_csv(PATH_TO_DATA+FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get runner information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KEY = '0187fcdf7ac3d90d68334afa03b87efe' # Decode Base64 string + Hex encoder\n",
    "IV = '33a39433e4dde7c4ddb9d4502b8905d4' # Decode Base64 string + Hex encoder\n",
    "KEY_BYTES = binascii.a2b_hex(KEY)\n",
    "IV_BYTES = binascii.a2b_hex(IV)\n",
    "CIPHER = AES.new(KEY_BYTES, AES.MODE_CBC, IV_BYTES, segment_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpad(string):\n",
    "    '''\n",
    "    Remove the PKCS#7 padding from a text string\n",
    "    '''\n",
    "\n",
    "    length = len(string)\n",
    "    pad_size = string[-1]\n",
    "    return string[:length - pad_size]\n",
    "\n",
    "\n",
    "def decrypt_data(cipher, encrypted):\n",
    "    '''\n",
    "    Decrypt data given key and iv\n",
    "    '''\n",
    "\n",
    "    decrypted = cipher.decrypt(binascii.a2b_base64(encrypted).rstrip())\n",
    "    return unpad(decrypted)\n",
    "\n",
    "\n",
    "def parse_html_runner_table(table, base_url='https://www.datasport.com'):\n",
    "\n",
    "    n_columns = 0\n",
    "    n_rows=0\n",
    "    column_names = []\n",
    "\n",
    "    # Find number of rows and columns\n",
    "    # we also find the column titles if we can\n",
    "    for row in table.find_all('tr'):\n",
    "\n",
    "        # Determine the number of rows in the table\n",
    "        td_tags = row.find_all('td')\n",
    "        if len(td_tags) > 0:\n",
    "            n_rows+=1\n",
    "            if n_columns == 0:\n",
    "                # Set the number of columns for our table\n",
    "                n_columns = len(td_tags)\n",
    "\n",
    "        # Handle column names if we find them\n",
    "        th_tags = row.find_all('th') \n",
    "        if len(th_tags) > 0 and len(column_names) == 0:\n",
    "            for th in th_tags:\n",
    "                column_names.append(th.get_text())\n",
    "\n",
    "    # Safeguard on Column Titles\n",
    "    if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "        raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "    columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "    df = pd.DataFrame(columns = columns,\n",
    "                      index= range(0,n_rows))\n",
    "    \n",
    "    \n",
    "    url_information_runner = []\n",
    "    row_marker = 0\n",
    "    for row in table.find_all('tr'):\n",
    "        column_marker = 0\n",
    "        \n",
    "        columns = row.find_all('td')\n",
    "        for index, column in enumerate(columns):\n",
    "            df.iat[row_marker,column_marker] = column.get_text()\n",
    "            \n",
    "            # add the url to get informations about the runners.\n",
    "            if(index == 1):\n",
    "                url_information_runner.append(base_url + column.find('a')['href'])\n",
    "                \n",
    "            column_marker += 1\n",
    "        if len(columns) > 0:\n",
    "            row_marker += 1\n",
    "\n",
    "    # Convert to float if possible\n",
    "    for col in df:\n",
    "        try:\n",
    "            df[col] = df[col].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    #print(url_information_runner)\n",
    "    # add columns url\n",
    "    df['url_run_event'] = pd.Series(url_information_runner)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_runner_information(acode_file='./Data/acode_2009_2015/unique_acode_2009_2015.csv', base_url='https://www.datasport.com/sys/myds/ajax/getDSInfo.htm?acode='):\n",
    "\n",
    "    data_acode = pd.read_csv(acode_file)\n",
    "\n",
    "    ATTRIBUTE_RUN = 'url_run_event'\n",
    "    for acode in data_acode['acode']:\n",
    "        \n",
    "        url = base_url + acode\n",
    "        \n",
    "        # We retrieve filters and store cookies for further calls to server\n",
    "        filters_page = rq.get(url)\n",
    "        cookies = filters_page.cookies.get_dict()\n",
    "        page = bfs(filters_page.text, 'html.parser')\n",
    "\n",
    "        # We get the birthyear\n",
    "        small_p = page.findAll('p', { 'class': 'small' })\n",
    "        birth_year = small_p[1].text.split(\" \")[1:][0]\n",
    "\n",
    "        # We get information on the table\n",
    "        table_run_event = page.find('table', { 'id': 'timeTable' })\n",
    "        information_runner = parse_html_runner_table(table_run_event)\n",
    "\n",
    "        for index, row in information_runner.iterrows():\n",
    "            url_ajax = row[ATTRIBUTE_RUN]\n",
    "            ajax_response = rq.get(url_ajax, cookies=cookies)\n",
    "            decrypted_response = decrypt_data(cipher=CIPHER, encrypted=ajax_response.text)\n",
    "            print(url_ajax)\n",
    "            print(decrypted_response)  \n",
    "            break\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_acode = pd.read_csv('./Data/acode_2009_2015/unique_acode_2009_2015.csv')\n",
    "data_acode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_runner_information()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
