{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bfs\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os.path\n",
    "import os\n",
    "from Crypto.Cipher import AES\n",
    "import binascii\n",
    "import json\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all acode (runner unique code) in a run event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML('<iframe src=https://services.datasport.com/2015/lauf/transviamala/alfaw.htm width=1000 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_acode(url):\n",
    "    alpha_page = rq.get(url)\n",
    "    alpha_page_soup = bfs(alpha_page.text, 'html5lib')\n",
    "\n",
    "    runners = alpha_page_soup.body.findAll('span', attrs={'class': 'myds'})\n",
    "    \n",
    "    return {runner['acode']: str.strip(runner.text) for runner in runners}\n",
    "\n",
    "def get_all_acode_from_run_event(url, file=False):\n",
    "    \n",
    "    if file and os.path.isfile(file):\n",
    "        print('Read acode from file: ' + file)\n",
    "        return pd.read_csv(file, index_col='acode').to_dict()['name']\n",
    "    \n",
    "    data = []\n",
    "    page = rq.get(url)\n",
    "    soup = bfs(page.text, 'html5lib')\n",
    "    table_links = soup.select('font > a[href*=ALF]')\n",
    "    all_acode = {}\n",
    "    if url[-1] != '/':\n",
    "        url += '/'\n",
    "    for idx, link in enumerate(table_links):\n",
    "        full_link = url + link['href']\n",
    "        \n",
    "        print(str(idx+1) + '/' + str(len(table_links)) + ' - Processing ' + full_link)\n",
    "\n",
    "        all_acode = {**all_acode, **get_all_acode(full_link)}\n",
    "        \n",
    "        time.sleep(random.uniform(0.1, 0.3))\n",
    "\n",
    "    if file:\n",
    "        print('Write acode in file: ' + file)\n",
    "        pd.Series(all_acode).to_csv(file, header=['name'], index_label='acode')\n",
    "        \n",
    "    return all_acode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#acode_list = get_all_acode_from_run_event('https://services.datasport.com/2009/diverse/trophy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(acode_list.items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get run events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML('<iframe src=https://www.datasport.com/en/Calendar/ width=1000 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_params_calendar():\n",
    "    calendar_page = rq.get('https://www.datasport.com/en/Calendar/')\n",
    "    calendar_soup = bfs(calendar_page.text, 'html5lib')\n",
    "\n",
    "    selector_table = calendar_soup.find('table', attrs={'id': 'ds-calendar-header'})\n",
    "\n",
    "    available_params = {}\n",
    "    for selector in selector_table.findAll('select'):\n",
    "        available_params[selector['name']] = {option.text: option['value'] for option in selector.findAll('option')}\n",
    "\n",
    "    return available_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calendar_available_params = get_all_params_calendar()\n",
    "#calendar_available_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all run events url in a calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_run_events_url(year=2009, month=1, country='CCH', sport='Running'):\n",
    "\n",
    "    calendar_params = {\n",
    "        'dr': '',\n",
    "        'lastQuery': 'D147BC896417D2D2B96FA1AADD893731',\n",
    "        'eventsearch': '',\n",
    "        'eventservice': 'all',\n",
    "        'start': 1,\n",
    "        'etyp': sport,\n",
    "        'eventlocation': country,\n",
    "        'eventmonth': month,\n",
    "        'eventyear': year,\n",
    "    }\n",
    "\n",
    "    calendar_page = rq.post('https://www.datasport.com/en/Calendar/', data = calendar_params)\n",
    "    calendar_soup = bfs(calendar_page.text, 'html5lib')\n",
    "\n",
    "    table = calendar_soup.find('table', attrs={'id': 'ds-calendar-body'})\n",
    "\n",
    "    all_event_url = {}\n",
    "    for row in table.findAll('tr'):\n",
    "        columns = row.findAll('td')\n",
    "        if len(columns) >= 4:\n",
    "            url = columns[4].find('a')\n",
    "            if url:\n",
    "                all_event_url[url['href']] = {\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'country': country,\n",
    "                    'sport': sport,\n",
    "                    'full_date': str.strip(columns[0].text),\n",
    "                    'name': str.strip(columns[1].text),\n",
    "                }\n",
    "\n",
    "    return all_event_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_run_events_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all run event urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_run_events():\n",
    "    run_events = {}\n",
    "    calendar_available_params = get_all_params_calendar()\n",
    "    for year_text, year_value in calendar_available_params['eventyear'].items():\n",
    "        if year_value != 'all':\n",
    "            for month_text, month_value in calendar_available_params['eventmonth'].items():\n",
    "                if month_value != 'all':\n",
    "                    print('Processing: Year ' + year_value + ' / Month ' + month_value)\n",
    "                    run_events = {**run_events,  **get_run_events_url(year_value, month_value)}\n",
    "                    time.sleep(random.uniform(0.5, 2))\n",
    "    return run_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_events = get_all_run_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_events_df = pd.DataFrame(run_events).T\n",
    "#run_events_df.index.name = 'url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_events_df.to_csv('Data/run_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head Data/run_events.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_events_df = pd.read_csv('Data/run_events.csv')\n",
    "run_events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all acode in all runs from 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_events_df_2009_2015 = run_events_df[[year >= 2009 and year < 2016 for year in run_events_df['year']]]\n",
    "#run_events_df_2009_2015.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run_events_df_2009_2015.to_csv('Data/run_events_2009_2015.csv', index_label='acode_index')\n",
    "!head Data/run_events_2009_2015.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_events_df_2009_2015 = pd.read_csv('Data/run_events_2009_2015.csv', index_col='acode_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_all_acode_from_list_run_event(run_events, path='Data/acode_2009_2015/'):\n",
    "    for run_event in run_events.itertuples():\n",
    "        print('Processing: Run \"' + run_event.name + '\" / Date ' + run_event.full_date + ' / Url ' + run_event.url)\n",
    "        get_all_acode_from_run_event(run_event.url, path + str(run_event.Index) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './Data/acode_2009_2015/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_acode_2009_2015 = get_all_acode_from_list_run_event(run_events_df_2009_2015, PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definir une mÃ©thode\n",
    "\n",
    "# get all data and remove the double\n",
    "file_list = os.listdir(PATH_TO_DATA)\n",
    "result_dataframe = pd.read_csv(PATH_TO_DATA + '1000.csv')\n",
    "for file in file_list:\n",
    "    pd.concat([result_dataframe, pd.read_csv(PATH_TO_DATA+file)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(result_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILE_NAME = 'unique_acode_2009_2015.csv'\n",
    "#if(len(result_dataframe['acode'].unique()) == len(result_dataframe)):\n",
    "#    result_dataframe.to_csv(PATH_TO_DATA+FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get runner information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "# DECRYPTION OF RUNNING INFORMATION #\n",
    "#####################################\n",
    "\n",
    "KEY = '0187fcdf7ac3d90d68334afa03b87efe' # Decode Base64 string + Hex encoder\n",
    "IV = '33a39433e4dde7c4ddb9d4502b8905d4' # Decode Base64 string + Hex encoder\n",
    "KEY_BYTES = binascii.a2b_hex(KEY)\n",
    "IV_BYTES = binascii.a2b_hex(IV)\n",
    "CIPHER = AES.new(KEY_BYTES, AES.MODE_CBC, IV_BYTES, segment_size=128)\n",
    "\n",
    "def unpad(string):\n",
    "    '''\n",
    "    This function removes the PKCS#7 padding from a text string.\n",
    "    \n",
    "    Parameters\n",
    "    string: data with padding\n",
    "    '''\n",
    "\n",
    "    length = len(string)\n",
    "    pad_size = string[-1]\n",
    "    return string[:length - pad_size]\n",
    "\n",
    "\n",
    "def decrypt_data(cipher, encrypted):\n",
    "    '''\n",
    "    This function decrypts data given key and iv.\n",
    "    \n",
    "    Parameters\n",
    "    cipher: AES cipher used to decrypt data\n",
    "    encrypted: encrypted data\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        decrypted = cipher.decrypt(binascii.a2b_base64(encrypted).rstrip())\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    return unpad(decrypted).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# HANDLE OF RUNNER'S INFORMATIONS #\n",
    "###################################\n",
    "\n",
    "def retrieve_runner_page(url):\n",
    "    '''\n",
    "    This function retrieves personal page's content of a runner and session cookies.\n",
    "    \n",
    "    Parameters\n",
    "    url: URL of personal page of a runner\n",
    "    '''\n",
    "    \n",
    "    filters_page = rq.get(url)\n",
    "    cookies = filters_page.cookies.get_dict()\n",
    "    page = bfs(filters_page.text, 'html.parser')\n",
    "    return page, cookies\n",
    "\n",
    "\n",
    "def retrieve_birthyear_location(page):\n",
    "    '''\n",
    "    This function retrieves birthyear and location of a runner in his personal page.\n",
    "    \n",
    "    Parameters\n",
    "    page: HTML page of a runner\n",
    "    '''\n",
    "    \n",
    "    small_p = page.findAll('p', { 'class': 'small' })\n",
    "    birthyear = small_p[1].text.split(\" \")[1:][0]\n",
    "    location = small_p[0].text.strip()\n",
    "    return birthyear, location\n",
    "\n",
    "\n",
    "def parse_html_runner_table(table, base_url='https://www.datasport.com'):\n",
    "    '''\n",
    "    This function transforms HTML table containing all runnings of a given runner into a pandas DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    table: HTML table to be parsed\n",
    "    base_url: root URL of website (by default, https://www.datasport.com)\n",
    "    '''\n",
    "    \n",
    "    n_columns = 0\n",
    "    n_rows=0\n",
    "    column_names = []\n",
    "\n",
    "    # First, we find number of rows and columns, but also column titles if we can\n",
    "    for row in table.find_all('tr'):\n",
    "\n",
    "        # We determine the number of rows in the table\n",
    "        td_tags = row.find_all('td')\n",
    "        if len(td_tags) > 0:\n",
    "            n_rows += 1\n",
    "            if n_columns == 0:\n",
    "                # We set the number of columns for our table\n",
    "                n_columns = len(td_tags)\n",
    "\n",
    "        # If we find column names, we store them\n",
    "        th_tags = row.find_all('th') \n",
    "        if len(th_tags) > 0 and len(column_names) == 0:\n",
    "            for th in th_tags:\n",
    "                column_names.append(th.get_text())\n",
    "\n",
    "    # We raise an exception if there is a problem with columns' structure\n",
    "    if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "        raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "    # We create pandas DataFrame according to HTML table structure\n",
    "    columns = column_names if len(column_names) > 0 else range(0, n_columns)\n",
    "    df = pd.DataFrame(columns = columns, index= range(0, n_rows))\n",
    "\n",
    "    url_information_runner = []\n",
    "    row_marker = 0\n",
    "    \n",
    "    # We retrieve all data of table\n",
    "    for row in table.find_all('tr'):\n",
    "        column_marker = 0\n",
    "\n",
    "        columns = row.find_all('td')\n",
    "        for index, column in enumerate(columns):\n",
    "            df.iat[row_marker,column_marker] = column.get_text()\n",
    "\n",
    "            # We add URL to get information about the runners\n",
    "            if(index == 1):\n",
    "                url_information_runner.append(base_url + column.find('a')['href'])\n",
    "\n",
    "            column_marker += 1\n",
    "            \n",
    "        if len(columns) > 0:\n",
    "            row_marker += 1\n",
    "\n",
    "    # We convert columns to float if possible\n",
    "    for col in df:\n",
    "        try:\n",
    "            df[col] = df[col].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # We finally add URL of running event in the DataFrame\n",
    "    df['url_run_event'] = pd.Series(url_information_runner)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieve_time_table(page):\n",
    "    '''\n",
    "    This function retrieves the time table (i.e. all runnings of a runner) in a given page.\n",
    "    \n",
    "    Parameters\n",
    "    page: HTML page to be parsed in order to recover the time table\n",
    "    '''\n",
    "    \n",
    "    table_run_event = page.find('table', {'id': 'timeTable'})\n",
    "    return parse_html_runner_table(table_run_event)\n",
    "\n",
    "\n",
    "def retrieve_running_information(information_runner, running_number, cookies):\n",
    "    '''\n",
    "    This function retrieves all the information of a running, given a runner.\n",
    "    \n",
    "    Parameters\n",
    "    information_runner: Information of the considered runner\n",
    "    running_number: Number associated to the running for which we want to recover information\n",
    "    cookies: Session cookies to use with GET request\n",
    "    '''\n",
    "    \n",
    "    time.sleep(random.uniform(0.5, 1))\n",
    "    ajax_response = rq.get(information_runner.iloc[[running_number]]['url_run_event'].values[0], cookies=cookies)\n",
    "    cipher = AES.new(KEY_BYTES, AES.MODE_CBC, IV_BYTES, segment_size=128)\n",
    "    return decrypt_data(cipher=cipher, encrypted=ajax_response.text)\n",
    "\n",
    "\n",
    "def force_retrieve(url, running_number):\n",
    "    '''\n",
    "    This function forces the retrieve of the running information using a new session.\n",
    "    \n",
    "    Parameters\n",
    "    url: URL of the personal page of runner\n",
    "    running_number: Number associated to the running for which we want to recover information\n",
    "    '''\n",
    "    \n",
    "    # We allow at most three (3) attempts\n",
    "    for i in range(0, 3):\n",
    "        page, cookies = retrieve_runner_page(url)\n",
    "        information_runner = retrieve_time_table(page)\n",
    "        decrypted_response = retrieve_running_information(information_runner, running_number, cookies)\n",
    "        if decrypted_response != None:\n",
    "            break\n",
    "    return decrypted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# RETRIEVE OF ALL RUNNERS' INFORMATION #\n",
    "########################################\n",
    "\n",
    "def get_runners_information(\n",
    "    acode_file='./Data/acode_2009_2015/unique_acode_2009_2015.csv',\n",
    "    base_url='https://www.datasport.com/sys/myds/ajax/getDSInfo.htm?acode=',\n",
    "    store_runners_information_file='./Data/runners.csv',\n",
    "    store_runs_information_file='./Data/runs.csv'):\n",
    "\n",
    "    data_acode = pd.read_csv(acode_file)\n",
    "    \n",
    "    data_runners = []\n",
    "    data_runs = []\n",
    "\n",
    "    print('Number of runners: ' + str(len(data_acode)))\n",
    "    \n",
    "    for idx_acode, row_acode in data_acode.iterrows():\n",
    "        \n",
    "        url = base_url + row_acode['acode']\n",
    "        \n",
    "        print('Runner acode ' + row_acode['acode'], end='')\n",
    "        \n",
    "        # We retrieve personal page of the runner and store cookies for further calls to server\n",
    "        page, cookies = retrieve_runner_page(url)\n",
    "\n",
    "        # We get the birthyear, location and all runnings associated to the runner\n",
    "        birthyear, location = retrieve_birthyear_location(page)\n",
    "        information_runner = retrieve_time_table(page)\n",
    "        \n",
    "        # We store personal information of the runner\n",
    "        data_runners.append({\n",
    "                'acode': row_acode['acode'],\n",
    "                'name': row_acode['name'],\n",
    "                'birthyear': birthyear,\n",
    "                'location': location\n",
    "            })\n",
    "\n",
    "        # We retrieve all runs of the runner\n",
    "        print(' / Number of runs: ' + str(len(information_runner)))\n",
    "        progress_bar = FloatProgress(min=0, max=len(information_runner))\n",
    "        display(progress_bar)\n",
    "\n",
    "        for idx_runner, row_runner in information_runner.iterrows():\n",
    "            \n",
    "            decrypted_response = retrieve_running_information(information_runner, idx_runner, cookies)\n",
    "\n",
    "            # We force retrieve using new session if decrypt process failed\n",
    "            if decrypted_response == None:\n",
    "                decrypted_response = force_retrieve(url, idx_runner)\n",
    "           \n",
    "            progress_bar.value += 1\n",
    "            \n",
    "            if decrypted_response == None:\n",
    "                print('FATAL ERROR')\n",
    "                print(row_acode['acode'])\n",
    "                print(idx_runner)\n",
    "                print(row_runner['url_run_event'])\n",
    "                print(url)\n",
    "                print('**********')\n",
    "                continue\n",
    "\n",
    "            running_information = json.loads(decrypted_response)\n",
    "            \n",
    "            data_runs.append({**running_information, 'acode': row_acode['acode']})\n",
    "        \n",
    "        # END OF LOOP ON RUNNINGS\n",
    "        \n",
    "        progress_bar.close()\n",
    "        \n",
    "    # END OF LOOP ON RUNNERS\n",
    "\n",
    "    df_data_runners = pd.DataFrame(data_runners)\n",
    "    df_data_runs = pd.DataFrame(data_runs)\n",
    "    \n",
    "    if store_runners_information_file:\n",
    "        df_data_runners.to_csv(store_runners_information_file, index=False)\n",
    "    if store_runs_information_file:\n",
    "        df_data_runs.to_csv(store_runs_information_file, index=False)\n",
    "\n",
    "    return [df_data_runners, df_data_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data_runners, df_data_runs = get_runners_information()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
